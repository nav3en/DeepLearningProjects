{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis of movie reviews with neural network \n",
    "\n",
    "This notebook contains code for building a neural network that takes reviews and uses a neural network to classify the sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    }
   ],
   "source": [
    "### Step 1 - Reading in the data\n",
    "\n",
    "# Open file read lines and get it into a list\n",
    "reviews=list()\n",
    "with open('reviews.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        reviews.append(line[:-1])\n",
    "\n",
    "labels=list()\n",
    "with open('labels.txt', 'r') as f1:\n",
    "    for label in f1.readlines():\n",
    "        labels.append(label[:-1].upper())\n",
    "print(len(reviews))\n",
    "# We have 25,000 reviews and their labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Step2 - Calculate word counts and ratios\n",
    "# Using counters to get word counts for all, positive and negative reviews\n",
    "total_counts=Counter()\n",
    "positive_counts=Counter()\n",
    "negative_counts=Counter()\n",
    " \n",
    "for i in range(len(reviews)):\n",
    "    if labels[i]=='POSITIVE':\n",
    "        for word in reviews[i].split(\" \"):\n",
    "            positive_counts[word] +=1\n",
    "            total_counts[word] +=1\n",
    "    else:\n",
    "        for word in reviews[i].split(\" \"):\n",
    "            negative_counts[word] +=1\n",
    "            total_counts[word] +=1\n",
    "            \n",
    "## To implement later -  ratio part "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 74074 words in the vocabulary\n"
     ]
    }
   ],
   "source": [
    "## Implement methods to update input layer\n",
    "\n",
    "## Find Length of vocabulary\n",
    "# using a set to extract unique words\n",
    "vocab = set(total_counts.keys())\n",
    "vocab_size = len(vocab)\n",
    "print(\"There are \"+str(vocab_size) + \" words in the vocabulary\")\n",
    "\n",
    "# Initialize a numpy vector/array with same length as vocab. This will serve as layer_0 or the input layer\n",
    "# This will help create a constant length vector to feed into the Neural network\n",
    "layer_0 = np.zeros((1, vocab_size))\n",
    "\n",
    "## Word to index dictionary\n",
    "word2index={}\n",
    "for i,word in enumerate(vocab):\n",
    "    word2index[word]=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Supporting methods\n",
    "def get_target_for_label(label):\n",
    "    return 1 if label=='POSITIVE' else 0\n",
    "\n",
    "def update_input_layer(review):\n",
    "    global layer_0\n",
    "    # Clearing contents of layer_0\n",
    "    layer_0 *=0\n",
    "    for word in review.split(\" \"):\n",
    "        layer_0[0][word2index[word]] = 1\n",
    "\n",
    "# Testing the method\n",
    "update_input_layer(reviews[0])   \n",
    "layer_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Step 3 - Building the Neural Network\n",
    "\n",
    "class NeuralNetwork(object):\n",
    "\n",
    "    def __init__(self, reviews,labels,hidden_nodes = 10, learning_rate = 0.1):\n",
    "\n",
    "        # Setting the seed for the random number generator\n",
    "        np.random.seed(1)\n",
    "        # Make a call to preprocess\n",
    "        self.preprocess_data(reviews,labels)\n",
    "        # Call the constructor\n",
    "        self.init_network(len(self.review_vocab),hidden_nodes, 1, learning_rate)\n",
    "        \n",
    "    \n",
    "    def preprocess_data(self,reviews,labels):\n",
    "        \n",
    "        # This preforms all the pre processing required to make sure \n",
    "        # calculating vocab size\n",
    "        review_vocab = set()\n",
    "        for i in range(len(reviews)):\n",
    "            for word in reviews[i].split(\" \"):\n",
    "                review_vocab.add(word)\n",
    "        self.review_vocab = list(review_vocab)\n",
    "        \n",
    "        label_vocab = set()\n",
    "        for label in labels:\n",
    "            label_vocab.add(label)\n",
    "        self.label_vocab = list(label_vocab)\n",
    "        \n",
    "        self.reviews_vocab_size = len(self.review_vocab)\n",
    "        self.labels_vocab_size = len(self.label_vocab)\n",
    "\n",
    "        # Initialize a numpy vector/array with same length as vocab. This will serve as layer_0 or the input layer\n",
    "        # This will help create a constant length vector to feed into the Neural network\n",
    "        \n",
    "\n",
    "        ## Word to index dictionary\n",
    "        self.word2index={}\n",
    "        for i,word in enumerate(self.review_vocab):\n",
    "            self.word2index[word]=i\n",
    "        \n",
    "        self.label2index = {}\n",
    "        for i, label in enumerate(self.label_vocab):\n",
    "            self.label2index[label] = i\n",
    "            \n",
    "    def init_network(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        # initialize the layers\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "        \n",
    "        \n",
    "        #Initialize the weights with zeros\n",
    "        self.weights_0_1 = np.zeros((self.input_nodes,self.hidden_nodes)) # Create a matrix of input_nodes x hidden_nodes\n",
    "        self.weights_1_2 = np.random.normal(0.0, self.output_nodes**-0.5,(self.hidden_nodes, self.output_nodes))\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        self.layer_0 = np.zeros((1, input_nodes))\n",
    "    \n",
    "    def sigmoid(self,x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    \n",
    "    def sigmoid_output_2_derivative(self,output):\n",
    "        return output * (1 - output)  \n",
    "    \n",
    "    def get_target_for_label(self, label):\n",
    "        return 1 if label=='POSITIVE' else 0\n",
    "\n",
    "    def update_input_layer(self, review):\n",
    "        # Clearing contents of layer_0\n",
    "        self.layer_0 *= 0\n",
    "        for word in review.split(\" \"):\n",
    "            if(word in self.word2index.keys()):\n",
    "                self.layer_0[0][self.word2index[word]] = 1\n",
    "                \n",
    "                \n",
    "\n",
    "    def train(self, training_reviews, training_labels):\n",
    "\n",
    "        assert(len(training_reviews) == len(training_labels))\n",
    "        \n",
    "        correct_so_far = 0\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        for i in range(len(training_reviews)):\n",
    "            review = training_reviews[i]\n",
    "            label = training_labels[i]\n",
    "\n",
    "            ## Forward pass            \n",
    "            \n",
    "            # Get the input layer set\n",
    "            self.update_input_layer(review.lower())\n",
    "            \n",
    "            # Hidden Layer\n",
    "            layer_1 = self.layer_0.dot(self.weights_0_1)\n",
    "            \n",
    "            #Output layer\n",
    "            layer_2 = self.sigmoid(layer_1.dot(self.weights_1_2))\n",
    "            \n",
    "        ##Backward propagation\n",
    "            \n",
    "            layer_2_error = layer_2 - self.get_target_for_label(label)\n",
    "            layer_2_delta = layer_2_error *self.sigmoid_output_2_derivative(layer_2)\n",
    "            \n",
    "            layer_1_error = layer_2_delta.dot(self.weights_1_2.T) \n",
    "            layer_1_delta= layer_1_error # Because we aren't applying any activation function here\n",
    "            \n",
    "            #Update weights\n",
    "            self.weights_1_2 -= layer_1.T.dot(layer_2_delta) * self.learning_rate \n",
    "            self.weights_0_1 -= self.layer_0.T.dot(layer_1_delta) * self.learning_rate            \n",
    "        \n",
    "            # Logging training progress\n",
    "            \n",
    "            if(np.abs(layer_2_error) < 0.5):\n",
    "                correct_so_far += 1\n",
    "            \n",
    "            reviews_per_second = i / float(time.time() - start)\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(training_reviews)))[:4] + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] + \" #Correct:\" + str(correct_so_far) + \" #Trained:\" + str(i+1) + \" Training Accuracy:\" + str(correct_so_far * 100 / float(i+1))[:4] + \"%\")\n",
    "            if(i % 2500 == 0):\n",
    "                print(\"\")\n",
    "                \n",
    "    def test(self, testing_reviews, testing_labels):\n",
    "        correct = 0\n",
    "        start = time.time()\n",
    "        \n",
    "        for i in range(len(testing_reviews)):\n",
    "            pred = self.run(testing_reviews[i])\n",
    "            if(pred == testing_labels[i]):\n",
    "                correct += 1\n",
    "            \n",
    "            reviews_per_second = i / float(time.time() - start)\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(testing_reviews)))[:4] \\\n",
    "                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n",
    "                            + \"% #Correct:\" + str(correct) + \" #Tested:\" + str(i+1) + \" Testing Accuracy:\" + str(correct * 100 / float(i+1))[:4] + \"%\")\n",
    " \n",
    "            \n",
    "    \n",
    "    def run(self, review):\n",
    "        # This is to process the data and generate outputs based on trained network\n",
    "\n",
    "        # This populates layer_0 with input values\n",
    "        # Input layer\n",
    "        self.update_input_layer(review.lower())\n",
    "        \n",
    "        # Hidden Layer\n",
    "        layer_1 = self.layer_0.dot(self.weights_0_1)\n",
    "\n",
    "        #Output layer\n",
    "        layer_2 = self.sigmoid(layer_1.dot(self.weights_1_2))\n",
    "        \n",
    "        # Returning the predicted class\n",
    "        if layer_2[0] > 0.5:\n",
    "            return \"POSITIVE\"\n",
    "        else:\n",
    "            return \"NEGATIVE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlp = NeuralNetwork(reviews[:-1000],labels[:-1000], learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:0.0% Speed(reviews/sec):0.0 #Correct:0 #Trained:1 Training Accuracy:0.0%\n",
      "Progress:10.4% Speed(reviews/sec):67.03 #Correct:1814 #Trained:2501 Training Accuracy:72.5%\n",
      "Progress:20.8% Speed(reviews/sec):88.40 #Correct:3776 #Trained:5001 Training Accuracy:75.5%\n",
      "Progress:31.2% Speed(reviews/sec):100.1 #Correct:5867 #Trained:7501 Training Accuracy:78.2%\n",
      "Progress:41.6% Speed(reviews/sec):107.3 #Correct:8009 #Trained:10001 Training Accuracy:80.0%\n",
      "Progress:52.0% Speed(reviews/sec):112.3 #Correct:10121 #Trained:12501 Training Accuracy:80.9%\n",
      "Progress:62.5% Speed(reviews/sec):115.7 #Correct:12247 #Trained:15001 Training Accuracy:81.6%\n",
      "Progress:72.9% Speed(reviews/sec):118.4 #Correct:14378 #Trained:17501 Training Accuracy:82.1%\n",
      "Progress:83.3% Speed(reviews/sec):120.4 #Correct:16557 #Trained:20001 Training Accuracy:82.7%\n",
      "Progress:93.7% Speed(reviews/sec):121.8 #Correct:18734 #Trained:22501 Training Accuracy:83.2%\n",
      "Progress:99.9% Speed(reviews/sec):122.6 #Correct:20049 #Trained:24000 Training Accuracy:83.5%"
     ]
    }
   ],
   "source": [
    "# train the network\n",
    "mlp.train(reviews[:-1000],labels[:-1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:99.9% Speed(reviews/sec):822.1% #Correct:500 #Tested:1000 Testing Accuracy:50.0%"
     ]
    }
   ],
   "source": [
    "mlp.test(reviews[-1000:],labels[-1000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.3.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
